# Model hyperparameters configuration.
# Modify these instead of constantly changing training or tuning scripts.

baseline:
  feature_col: 'w60_return_std'
  z_thresholds: [1.0, 1.5, 2.0, 2.5, 3.0]

logistic_regression:
  max_iter: 10000
  # class_weight: 'balanced'
  class_weight: 'balanced'
  solver: 'saga'
  penalty: 'l1'
  # l1_ratio: 0.5
  C: 0.01
  random_state: 23

xgboost:
  n_estimators: 200
  max_depth: 5
  learning_rate: 0.1
  min_child_weight: 1
  subsample: 0.8
  colsample_bytree: 0.8
  reg_alpha: 0.0
  reg_lambda: 1.0
  random_state: 23
  eval_metric: 'aucpr'
  # top_features: []

lightgbm:
  n_estimators: 200
  max_depth: 5
  learning_rate: 0.1
  min_child_weight: 1
  subsample: 0.8
  colsample_bytree: 0.8
  reg_alpha: 0.0
  reg_lambda: 1.0
  random_state: 23
  verbose: -1

# Regularized XGBoost preset for comparison.
xgboost_regularized:
  n_estimators: 400
  early_stopping_rounds: 50
  max_depth: 2
  learning_rate: 0.01
  min_child_weight: 10
  subsample: 0.6
  colsample_bytree: 0.7
  reg_alpha: 0.1
  reg_lambda: 10
  random_state: 23
  eval_metric: 'aucpr'
